data:
  # store with absolute path
  # not implemented yet
  # Real Voice leaveout number
  train_json: '/net/papilio/storage2/yhaoyuan/LAbyLM/new_dataset/train_trimmed_mapping.json'
  valid_json: '/net/papilio/storage2/yhaoyuan/LAbyLM/new_dataset/valid_trimmed_mapping.json'
  test_json: '/net/papilio/storage2/yhaoyuan/LAbyLM/new_dataset/test_trimmed_mapping.json'
  max_len: 100 # 150 # 200 for SpokenCOCO
  # image_resolution: 256

i2u:
  #### Used when inferencing
  model: "../../model/I2U/trimmed_mapping_SpeakerALL_Color/BEST_checkpoint_coco_2_cap_per_img_1_min_word_freq_gpu.pth.tar" # leave out colors
  wordmap: "../../data/processed/trimmed_mapping_SpeakerALL_Color/WORDMAP_coco_2_cap_per_img_1_min_word_freq.json" # leave out colors
  
  #### Used when training models
  captions_per_image: 4 #取决于 每一张图片对应多少个caption！比如 “Apple” "An apple in a white background" "It's an apple in a white background." 那就是3个caption
  min_word_freq: 1
  
  # dir_name: origin_4_captions_256_hubert_sentence
  # dir_name: origin_3_captions_256_hubert_sentence
  # dir_name: SpokenCOCO_5_captions_hubert_256
  # dir_name: Komatsu_4_captions_all_224
  dir_name: komatsu_4_captions_224_hubert
  # dir_name: komatsu_4_captions_256_hubert
  # dir_name: komatsu_4_captions_256_hubert_5_percent
  # dir_name: komatsu_4_captions_256_hubert_10_percent
  # dir_name: komatsu_4_captions_256_hubert_20_percent
  # dir_name: synthesize_speech

  # captions_per_image: 2 
  # min_word_freq: 1
  # dir_name: trimmed_mapping_SpeakerALL
  
  # captions_per_image: 4 
  # min_word_freq: 1
  # dir_name: Komatsu_4_captions_all_224
  


  #### Model params
  # batch_size: 32
  # num_workers: 10
  # epoch: 80

  train_params:
    batch_size: 64 # 64
    num_workers: 10
    grad_clip: 5.
    lr: 1.0e-3 # set to 4.0e-4 if scheduler = False
    optimizer: "Adam" # [Adam, AdamW]
    epoch: 50 # 50
    warmup_epoch: 5 # 5 only make sense when use_scheduler = True
    use_scheduler: True # True
    print_freq: 100
    kl_weight: 0.01
    checkpoint_path: # /net/papilio/storage2/yhaoyuan/transformer_I2S/saved_model/I2U/VC_5_captions_224/fixed_img_1024_no_sentence/bleu-4_BEST_checkpoint_coco_5_cap_per_img_1_min_word_freq_gpu.pth.tar
    gated_decoder: False
    load_uLM: False
    freeze_uLM: False
    freeze_uLM_hard: False
    
  model_params:
    d_model: 1024 # 2048
    nhead: 16 # 32
    num_layers: 12 # 6
    activation: "gelu"
    layer_norm_eps: 1.0e-5
    batch_first: True
    norm_first : True
    dropout: 0.1
    image_backbone: "ViT" #" ResNet"
    use_sentence_encoder: True
    sentence_embed: 8 #16
    fine_tune_image_encoder: False # Fine tune ResNet's last few layers if image_backbone is "ResNet"
    use_refine_encoder: False
    use_global_feature: False
    AR: True

  # refine_encoder_params:
  #   input_resolution: 14
  #   depth: 3
  #   num_heads: 8
  #   window_size: 14  # =14 退化为普通MSA结构
  #   shift_size: 0    # =0  无SW-MSA，仅W-MSA
  #   mlp_ratio: 4
  refine_encoder_params:
    input_resolution: 7 # 14
    depth: 3
    num_heads: 8
    window_size: 7  # =14 退化为普通MSA结构
    shift_size: 0    # =0  无SW-MSA，仅W-MSA
    mlp_ratio: 4

# 存储模型请将config一起存储
