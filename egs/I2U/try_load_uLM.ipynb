{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "from models import TransformerLM, TransformerConditionedLM\n",
    "import torch.nn.functional as F\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uLM_checkpoint_path = \"/net/papilio/storage2/yhaoyuan/transformer_I2S/gslm_models/uLM/hubert100_lm/checkpoint_best.pt\"\n",
    "checkpoint = torch.load(uLM_checkpoint_path)\n",
    "uLM_state_dict = checkpoint[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerLM(\n",
    "    vocab_size=104,\n",
    "    d_model=1024,\n",
    "    nhead=16,\n",
    "    num_layers=12,\n",
    "    activation=\"relu\",\n",
    "    layer_norm_eps=1e-5,\n",
    "    batch_first=True,\n",
    "    norm_first=True,\n",
    "    classifier_bias=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.weight\n",
      "tensor([[ 0.0393, -0.0569,  0.0812,  ...,  0.0961,  0.0389, -0.0317],\n",
      "        [-0.0721, -0.0568, -0.0007,  ...,  0.0997, -0.0921, -0.0186],\n",
      "        [ 0.0017,  0.0506,  0.0050,  ..., -0.0804,  0.0531, -0.0834],\n",
      "        ...,\n",
      "        [ 0.0706,  0.0569,  0.0035,  ...,  0.0178,  0.0548,  0.0307],\n",
      "        [-0.0836,  0.0109, -0.0821,  ...,  0.0065, -0.0768,  0.0746],\n",
      "        [-0.0314,  0.0458, -0.0280,  ..., -0.0913, -0.0764,  0.0452]])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in model.state_dict().items():\n",
    "#     print(k)\n",
    "#     print(model.state_dict()[k].shape)\n",
    "#     #print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in uLM_state_dict.items():\n",
    "#     print(k)\n",
    "#     print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor Initial Embedding:\\nprefix\\n    None                       decoder.\\n\\n    embed.weight:              embed_tokens.weight\\n\\nFor Each Layer:\\nprefix: \\n    LM_decoder.layers.[].      decoder.layers.[].\\n\\n    self_attn.in_proj_weight : self_attn.q_proj.weight\\n                               self_attn.k_proj.weight\\n                               self_attn.v_proj.weight\\n    self_attn.in_proj_bias :   self_attn.q_proj.bias\\n                               self_attn.k_proj.bias\\n                               self_attn.v_proj.bias\\n    self_attn.out_proj.weight: self_attn.out_proj.weight\\n    self_attn.out_proj.bias:   self_attn.out_proj.bias\\n    linear1.weight:            fc1.weight\\n    linear1.bias:              fc1.bias\\n    linear2.weight:            fc2.weight\\n    linear2.bias:              fc2.bias\\n    norm1.weight:              self_attn_layer_norm.weight\\n    norm1.bias:                self_attn_layer_norm.bias\\n    norm2.weight:              final_layer_norm.weight\\n    norm2.bias:                final_layer_norm.bias\\n\\nFor Final Layer:\\nprefix:\\n    LM_decoder.                decoder.\\n\\n    norm.weight:               layer_norm.weight\\n    norm.bias:                 layer_norm.bias\\n\\nClassifier:\\nprefix:\\n    None                       decoder.\\n    \\n    classifier.weight:         output_projection.weight\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Initial Embedding:\n",
    "prefix\n",
    "    None                       decoder.\n",
    "\n",
    "    embed.weight:              embed_tokens.weight\n",
    "\n",
    "For Each Layer:\n",
    "prefix: \n",
    "    LM_decoder.layers.[].      decoder.layers.[].\n",
    "\n",
    "    self_attn.in_proj_weight : self_attn.q_proj.weight\n",
    "                               self_attn.k_proj.weight\n",
    "                               self_attn.v_proj.weight\n",
    "    self_attn.in_proj_bias :   self_attn.q_proj.bias\n",
    "                               self_attn.k_proj.bias\n",
    "                               self_attn.v_proj.bias\n",
    "    self_attn.out_proj.weight: self_attn.out_proj.weight\n",
    "    self_attn.out_proj.bias:   self_attn.out_proj.bias\n",
    "    linear1.weight:            fc1.weight\n",
    "    linear1.bias:              fc1.bias\n",
    "    linear2.weight:            fc2.weight\n",
    "    linear2.bias:              fc2.bias\n",
    "    norm1.weight:              self_attn_layer_norm.weight\n",
    "    norm1.bias:                self_attn_layer_norm.bias\n",
    "    norm2.weight:              final_layer_norm.weight\n",
    "    norm2.bias:                final_layer_norm.bias\n",
    "\n",
    "For Final Layer:\n",
    "prefix:\n",
    "    LM_decoder.                decoder.\n",
    "\n",
    "    norm.weight:               layer_norm.weight\n",
    "    norm.bias:                 layer_norm.bias\n",
    "\n",
    "Classifier:\n",
    "prefix:\n",
    "    None                       decoder.\n",
    "    \n",
    "    classifier.weight:         output_projection.weight\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_key(tgt_state_dict, key, value):\n",
    "    model = tgt_state_dict\n",
    "    # Make sure the loaded values won't cause errors\n",
    "    assert model[key].shape == value.shape, f\"Key {key}, need shape {model[key].shape}, get shape {value.shape}\"\n",
    "    assert model[key].dtype == value.dtype, f\"Key {key}, need type {model[key].dtype}, get type {value.dtype}\"\n",
    "    model[key] = value\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_layer(tgt_state_dict, src_state_dict, layer_id):\n",
    "    # Load in_proj weight and bias\n",
    "    tgt_prefix = f\"LM_decoder.layers.{int(layer_id)}.\"\n",
    "    src_prefix = f\"decoder.layers.{int(layer_id)}.\"\n",
    "    src_q_weight = src_state_dict[src_prefix + \"self_attn.q_proj.weight\"]\n",
    "    src_q_bias = src_state_dict[src_prefix + \"self_attn.q_proj.bias\"]\n",
    "    src_k_weight = src_state_dict[src_prefix + \"self_attn.k_proj.weight\"]\n",
    "    src_k_bias = src_state_dict[src_prefix + \"self_attn.k_proj.bias\"]\n",
    "    src_v_weight = src_state_dict[src_prefix + \"self_attn.v_proj.weight\"]\n",
    "    src_v_bias = src_state_dict[src_prefix + \"self_attn.v_proj.bias\"]\n",
    "    \n",
    "    in_proj_weight = torch.cat((src_q_weight,src_k_weight,src_v_weight), dim=0)\n",
    "    in_proj_bias = torch.cat((src_q_bias,src_k_bias,src_v_bias), dim=0)\n",
    "    \n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"self_attn.in_proj_weight\", in_proj_weight)\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"self_attn.in_proj_bias\", in_proj_bias)\n",
    "\n",
    "    # load others\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"self_attn.out_proj.weight\", src_state_dict[src_prefix + \"self_attn.out_proj.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"self_attn.out_proj.bias\", src_state_dict[src_prefix + \"self_attn.out_proj.bias\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"linear1.weight\", src_state_dict[src_prefix + \"fc1.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"linear1.bias\", src_state_dict[src_prefix + \"fc1.bias\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"linear2.weight\", src_state_dict[src_prefix + \"fc2.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"linear2.bias\", src_state_dict[src_prefix + \"fc2.bias\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"norm1.weight\", src_state_dict[src_prefix + \"self_attn_layer_norm.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"norm1.bias\", src_state_dict[src_prefix + \"self_attn_layer_norm.bias\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"norm2.weight\", src_state_dict[src_prefix + \"final_layer_norm.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, tgt_prefix+\"norm2.bias\", src_state_dict[src_prefix + \"final_layer_norm.bias\"])\n",
    "    # print(tgt_state_dict[tgt_prefix+\"self_attn.in_proj_weight\"])\n",
    "    # print(src_q_weight)\n",
    "    #print(src_v_weight)\n",
    "    return tgt_state_dict\n",
    "\n",
    "def load_embed(tgt_state_dict, src_state_dict):\n",
    "    tgt_state_dict = load_key(tgt_state_dict, \"embed.weight\", src_state_dict[\"decoder.embed_tokens.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, \"classifier.weight\", src_state_dict[\"decoder.output_projection.weight\"])\n",
    "    return tgt_state_dict\n",
    "\n",
    "def load_final_norm(tgt_state_dict, src_state_dict):\n",
    "    tgt_state_dict = load_key(tgt_state_dict, \"LM_decoder.norm.weight\", src_state_dict[\"decoder.layer_norm.weight\"])\n",
    "    tgt_state_dict = load_key(tgt_state_dict, \"LM_decoder.norm.bias\", src_state_dict[\"decoder.layer_norm.bias\"])\n",
    "    return tgt_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = load_embed(model_state_dict, uLM_state_dict)\n",
    "model_state_dict = load_final_norm(model_state_dict, uLM_state_dict)\n",
    "for i in range(12):\n",
    "    model_state_dict = load_layer(model_state_dict, uLM_state_dict, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.weight\n",
      "tensor([[ 0.0393, -0.0569,  0.0812,  ...,  0.0961,  0.0389, -0.0317],\n",
      "        [-0.0721, -0.0568, -0.0007,  ...,  0.0997, -0.0921, -0.0186],\n",
      "        [ 0.0017,  0.0506,  0.0050,  ..., -0.0804,  0.0531, -0.0834],\n",
      "        ...,\n",
      "        [ 0.0706,  0.0569,  0.0035,  ...,  0.0178,  0.0548,  0.0307],\n",
      "        [-0.0836,  0.0109, -0.0821,  ...,  0.0065, -0.0768,  0.0746],\n",
      "        [-0.0314,  0.0458, -0.0280,  ..., -0.0913, -0.0764,  0.0452]])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0534,  0.0380, -0.1919,  ..., -0.1920, -0.0940, -0.0767],\n",
      "        [-0.0703,  0.0638, -0.1917,  ..., -0.1895, -0.0715, -0.0443],\n",
      "        [-0.0107, -0.0076, -0.0311,  ..., -0.0222, -0.1194, -0.0261],\n",
      "        ...,\n",
      "        [-0.0319,  0.0427,  0.0266,  ...,  0.0098, -0.0749,  0.0232],\n",
      "        [ 0.0108,  0.0111,  0.0388,  ..., -0.0373, -0.0581, -0.0033],\n",
      "        [ 0.0684, -0.0652, -0.0375,  ..., -0.0121, -0.0370, -0.0023]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerLM(\n",
       "  (embed): Embedding(104, 1024)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (LM_decoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=104, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16],\n",
      "        [ 2, 75, 16]])\n",
      "tensor([[[-0.2129,  1.1702,  2.6507,  ...,  0.2212,  0.1652, -0.0551],\n",
      "         [-0.2535,  1.1923,  2.6548,  ...,  0.1870,  0.1670, -0.0985],\n",
      "         [-0.3158,  1.2271,  2.6061,  ...,  0.1849,  0.1543, -0.1002]],\n",
      "\n",
      "        [[-0.2129,  1.1702,  2.6507,  ...,  0.2212,  0.1652, -0.0551],\n",
      "         [-0.2535,  1.1923,  2.6548,  ...,  0.1870,  0.1670, -0.0985],\n",
      "         [-0.3158,  1.2271,  2.6061,  ...,  0.1849,  0.1543, -0.1002]],\n",
      "\n",
      "        [[-0.2129,  1.1702,  2.6507,  ...,  0.2212,  0.1652, -0.0551],\n",
      "         [-0.2535,  1.1923,  2.6548,  ...,  0.1870,  0.1670, -0.0985],\n",
      "         [-0.3158,  1.2271,  2.6061,  ...,  0.1849,  0.1543, -0.1002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2129,  1.1702,  2.6507,  ...,  0.2212,  0.1652, -0.0551],\n",
      "         [-0.2535,  1.1923,  2.6548,  ...,  0.1870,  0.1670, -0.0985],\n",
      "         [-0.3158,  1.2271,  2.6061,  ...,  0.1849,  0.1543, -0.1002]],\n",
      "\n",
      "        [[-0.2129,  1.1702,  2.6507,  ...,  0.2212,  0.1652, -0.0551],\n",
      "         [-0.2535,  1.1923,  2.6548,  ...,  0.1870,  0.1670, -0.0985],\n",
      "         [-0.3158,  1.2271,  2.6061,  ...,  0.1849,  0.1543, -0.1002]],\n",
      "\n",
      "        [[-0.2129,  1.1702,  2.6507,  ...,  0.2212,  0.1652, -0.0551],\n",
      "         [-0.2535,  1.1923,  2.6548,  ...,  0.1870,  0.1670, -0.0985],\n",
      "         [-0.3158,  1.2271,  2.6061,  ...,  0.1849,  0.1543, -0.1002]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "k_prev_words = torch.LongTensor([[2, 75, 16]] * k)\n",
    "seqs = k_prev_words  # (k, 1)\n",
    "print(seqs)\n",
    "# Tensor to store top k sequences' scores; now they're just 0\n",
    "top_k_scores = torch.zeros(k, 1)  # (k, 1)\n",
    "# Lists to store completed sequences and scores\n",
    "complete_seqs = list()\n",
    "complete_seqs_scores = list()\n",
    "# Start decoding\n",
    "step = 5\n",
    "\n",
    "x = model.embed(seqs)\n",
    "x = model.pos_encoder(x)\n",
    "output = model.LM_decoder(x)\n",
    "print(output)\n",
    "scores = model.classifier(output[:,-1,:])\n",
    "scores = F.log_softmax(scores, dim=1)\n",
    "# Add\n",
    "scores = top_k_scores.expand_as(scores) + scores  # (s, vocab_size)\n",
    "if step == 1:\n",
    "    top_k_scores, top_k_words = scores[0].topk(k, 0, True, True)  # (s)\n",
    "else:\n",
    "    # Unroll and find top scores, and their unrolled indices\n",
    "    top_k_scores, top_k_words = scores.view(-1).topk(k, 0, True, True)  # (s)\n",
    "\n",
    "prev_word_inds = torch.div(top_k_words, 104, rounding_mode=\"floor\")\n",
    "next_word_inds = top_k_words % 104  # (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 2, 6, 4, 7, 8, 9, 5, 0])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 75]])\n",
      "tensor([[[-0.2359,  1.1805,  1.9810,  ...,  0.0401, -0.1347,  0.2386],\n",
      "         [-0.2661,  1.1961,  1.9554,  ...,  0.0164, -0.1628,  0.2259]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "k_prev_words = torch.LongTensor([[2, 75]] * k)\n",
    "seqs = k_prev_words  # (k, 1)\n",
    "print(seqs)\n",
    "# Tensor to store top k sequences' scores; now they're just 0\n",
    "top_k_scores = torch.zeros(k, 1)  # (k, 1)\n",
    "# Lists to store completed sequences and scores\n",
    "complete_seqs = list()\n",
    "complete_seqs_scores = list()\n",
    "# Start decoding\n",
    "\n",
    "x = model.embed(seqs)\n",
    "x = model.pos_encoder(x)\n",
    "output = model.LM_decoder(x)\n",
    "print(output)\n",
    "scores = model.classifier(output)\n",
    "scores = F.log_softmax(scores, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torcheval.metrics.text import Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5257, dtype=torch.float64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric=Perplexity()\n",
    "input = torch.tensor([[[0.3659, 0.7025, 0.3104]], [[0.0097, 0.6577, 0.1947]],[[0.5659, 0.0025, 0.0104]], [[0.9097, 0.0577, 0.7947]]])\n",
    "target = torch.tensor([[2],  [1], [2],  [1]])\n",
    "metric.update(input, target)\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torcheval.metrics.text.perplexity.Perplexity at 0x7f291103e160>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([[[0.3659, 0.1025, 0.1104]], [[0.8097, 0.6577, 0.1947]],[[0.5659, 0.0025, 0.0104]], [[0.9097, 0.0577, 0.7947]]])\n",
    "target = torch.tensor([[2],  [1], [2],  [1]])\n",
    "metric.update(input, target)\n",
    "#pp = metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6732, dtype=torch.float64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encodec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "094c9ae320a962664ae725268b2caa008c72eeabdfac83f71f78104cf05452c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
