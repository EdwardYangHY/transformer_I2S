{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "torch.version.cuda\n",
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = \"../data/processed/trimmed_mapping_SpeakerALL/train_image_paths.pickle\"\n",
    "train_cap_len = \"../data/processed/trimmed_mapping_SpeakerALL/TRAIN_CAPLENS_coco_2_cap_per_img_1_min_word_freq.json\"\n",
    "valid_img = \"../data/processed/trimmed_mapping_SpeakerALL/val_image_paths.pickle\"\n",
    "valid_cap_len = \"../data/processed/trimmed_mapping_SpeakerALL/VAL_CAPLENS_coco_2_cap_per_img_1_min_word_freq.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def read_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = read_pickle(train_img)\n",
    "train_cap_len = read_json(train_cap_len)\n",
    "valid_img = read_pickle(valid_img)\n",
    "valid_cap_len = read_json(valid_cap_len)\n",
    "train_avg_len = np.mean(train_cap_len)\n",
    "valid_avg_len = np.mean(valid_cap_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = \"../data/processed/encodec1/train_image_paths.pickle\"\n",
    "train_cap_len = \"../data/processed/encodec1/TRAIN_CAPLENS_coco_1_cap_per_img_1_min_word_freq.json\"\n",
    "valid_img = \"../data/processed/encodec1/val_image_paths.pickle\"\n",
    "valid_cap_len = \"../data/processed/encodec1/VAL_CAPLENS_coco_1_cap_per_img_1_min_word_freq.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = read_pickle(train_img)\n",
    "train_cap_len = read_json(train_cap_len)\n",
    "valid_img = read_pickle(valid_img)\n",
    "valid_cap_len = read_json(valid_cap_len)\n",
    "train_avg_len = np.mean(train_cap_len)\n",
    "valid_avg_len = np.mean(valid_cap_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275.2640949554896"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_VALLE_mask(img_len, seq_len) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        来自原来的function\n",
    "        math:`(L, S)` or :math:`(N\\cdot\\text{num\\_heads}, L, S)`, where :math:`N` is the batch size,\n",
    "        math:`L` is the target sequence length, and :math:`S` is the source sequence length.\n",
    "\n",
    "        args : \n",
    "            img_len : input image_features len. \n",
    "                        e.g.: [batch, feature_size, feature_size, dim] -> [batch, feature_size x feature_size, dim]\n",
    "                        img_len = feature_size x feature_size\n",
    "            seq_len : input seq len. e.g.: number of tokens.\n",
    "        e.g.:\n",
    "        if img_len = 4, seq_len = 5, it'll be like:\n",
    "            [[0.,   0.,   0.,   0., -inf, -inf, -inf, -inf, -inf],\n",
    "             [0.,   0.,   0.,   0., -inf, -inf, -inf, -inf, -inf],\n",
    "             [0.,   0.,   0.,   0., -inf, -inf, -inf, -inf, -inf],\n",
    "             [0.,   0.,   0.,   0., -inf, -inf, -inf, -inf, -inf],\n",
    "             [0.,   0.,   0.,   0.,   0., -inf, -inf, -inf, -inf],\n",
    "             [0.,   0.,   0.,   0.,   0.,   0., -inf, -inf, -inf],\n",
    "             [0.,   0.,   0.,   0.,   0.,   0.,   0., -inf, -inf],\n",
    "             [0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., -inf],\n",
    "             [0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]]\n",
    "        \"\"\"\n",
    "        \n",
    "        up = torch.full((img_len, img_len + seq_len), float(0))\n",
    "        up[:,img_len:] = float(\"-inf\")\n",
    "        down = torch.triu(torch.full((seq_len, img_len + seq_len), float('-inf')), diagonal=img_len+1)\n",
    "\n",
    "        mask = torch.cat([up, down], dim = 0)\n",
    "        # 重新设计mask\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_len = 1\n",
    "seq_len = 5\n",
    "generate_VALLE_mask(img_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encodec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "094c9ae320a962664ae725268b2caa008c72eeabdfac83f71f78104cf05452c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
