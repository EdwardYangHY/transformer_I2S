data:
  # store with absolute path
  # not implemented yet
  # Real Voice leaveout number
  # train_json: '/net/papilio/storage2/yhaoyuan/LAbyLM/new_dataset/train_trimmed_mapping.json'
  # valid_json: '/net/papilio/storage2/yhaoyuan/LAbyLM/new_dataset/valid_trimmed_mapping.json'
  # test_json: '/net/papilio/storage2/yhaoyuan/LAbyLM/new_dataset/test_trimmed_mapping.json'
  dataset_json: /net/papilio/storage2/yhaoyuan/transformer_I2S/data/food_dataset_sentence_embedding.json
  wav_captions: /net/papilio/storage2/yhaoyuan/transformer_I2S/data/captions_original/audios_trimmed_selet_hbcaps.json
  max_len: 200
  image_resolution: 256

u2s:
  # In domain
  # tacotron2: "../../saved_model/U2S/ourdir_mapping_warmstart_from_gtts/checkpoint_47000"

  # Out of Domain
  tacotron2: "../../saved_model/U2S/outdir_origin/checkpoint_76000"
  max_decoder_steps: 500
  
  batch_size: 64
  filelists_train: "../../data/U2S/filelists_gtts_hubert/ljs_audio_text_train_filelist.txt"
  filelists_val: "../../data/U2S/filelists_gtts_hubert/ljs_audio_text_val_filelist.txt"
  
  #### hifigan as vocoder of the system ####
  # make sure that hifigan's sr are the same with tacotron2
  hifigan: "../../hifigan/FOOD_V1_24K_Speaker3/generator_v1_24k"

asr:
  model_path: "/net/papilio/storage2/yhaoyuan/LAbyLM/model/ASR/wav2vec2-base-tuned/checkpoint-3000"
  # model_path: "/net/papilio/storage2/yhaoyuan/transformer_I2S/saved_model/ASR/wav2vec2-base-tuned-ljs/checkpoint-4000"

i2u:
  #### Used when inferencing
  # model: "../../model/I2U/trimmed_mapping_SpeakerALL_Color/BEST_checkpoint_coco_2_cap_per_img_1_min_word_freq_gpu.pth.tar" # leave out colors
  # wordmap: "../../data/processed/trimmed_mapping_SpeakerALL_Color/WORDMAP_coco_2_cap_per_img_1_min_word_freq.json" # leave out colors
  # model: "../../saved_model/I2U/VC_5_captions/23-02-10_20:10:09_sentence/bleu-4_BEST_checkpoint_coco_5_cap_per_img_1_min_word_freq_gpu.pth.tar"
  # model_config: "../../saved_model/I2U/VC_5_captions/23-02-10_20:10:09_sentence/config.yml"
  # wordmap: "../../data/processed/VC_5_captions/WORDMAP_coco_5_cap_per_img_1_min_word_freq.json"
  model: ../../saved_model/I2U/Komatsu_4_captions_all_224/beam_no_uLM_8_sentence/bleu-4_BEST_checkpoint_coco_4_cap_per_img_1_min_word_freq_gpu.pth.tar
  wordmap: ../../data/processed/Komatsu_4_captions_all_224/WORDMAP_coco_4_cap_per_img_1_min_word_freq.json
  
  #### Used when training models
  captions_per_image: 4 #取决于 每一张图片对应多少个caption！比如 “Apple” "An apple in a white background" "It's an apple in a white background." 那就是3个caption
  #captions_per_image: 1 # change it after LJS U2U
  min_word_freq: 1
  # dir_name: "trimmed_mapping_SpeakerALL" #"trimmed_mapping_SpeakerFixed"
  # dir_name: "encodec1"
  # dir_name: "trimmed_mapping_SpeakerALL_Color"
  # dir_name: VC_5_captions_320
  dir_name: origin_4_captions_256_hubert_sentence

  #### Model params
  # batch_size: 32
  # num_workers: 10
  # epoch: 80

  train_params:
    batch_size: 64
    num_workers: 10
    grad_clip: 5.
    lr: 1.0e-2 # set to 4.0e-4 if scheduler = False
    optimizer: "Adam" # [Adam, AdamW]
    epoch: 200
    warmup_epoch: 20 # only make sense when use_scheduler = True
    use_scheduler: True
    print_freq: 100
    kl_weight: 0.01
    checkpoint_path: #"/net/papilio/storage2/yhaoyuan/transformer_I2U/saved_model/I2U/encodec1/bleu-4_BEST_checkpoint_coco_1_cap_per_img_1_min_word_freq.pth.tar"


  model_params:
    d_model: 1024 # 1024
    nhead: 16 # 8
    num_layers: 12 # 6
    activation: "gelu"
    layer_norm_eps: 1.0e-5
    batch_first: True
    norm_first : True
    dropout: 0.1
    image_backbone: "ResNet"
    fine_tune_image_encoder: False # Fine tune ResNet's last few layers if image_backbone is "ResNet"
    use_refine_encoder: False # True
    use_global_feature: False # True
    AR: True

  refine_encoder_params:
    input_resolution: 7 # 14
    depth: 3
    num_heads: 8
    window_size: 7  # =14 退化为普通MSA结构
    shift_size: 0    # =0  无SW-MSA，仅W-MSA
    mlp_ratio: 4

# 存储模型请将config一起存储
rl:
  learning_rate: 0.0001
  buffer_size: 1000
  learning_starts: 0
  batch_size: 32
  total_timesteps_dqn: 50000
  total_timesteps_ddpg: 50000
  eval_freq_dqn: 200
  eval_freq_ddpg: 200
  n_eval_episodes_dqn: 1000
  n_eval_episodes_ddpg: 1000
  action_noise_sigma: 0.1
  eval_log_path_dqn: "./logs_dqn/"
  eval_log_path_ddpg: "./logs_ddpg/"
  incremental: false